{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gzuv2run9Yxa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5MpBxb2MjsO"
   },
   "source": [
    "## Датасет\n",
    "\n",
    "Прежде чем разбираться с моделями, нам надо в первую очередь разобраться с тем, как грузить датасет. Давайте напишем класс в торче для этого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h72XzlyfMZek"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name = self.data_df.iloc[idx]['img']\n",
    "        label = self.data_df.iloc[idx]['sing2']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"/media/murad/SSD/krasn/train_dataset_train/train/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()#to(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7URcg7KlMqbV"
   },
   "outputs": [],
   "source": [
    "# задаем преобразование изображения.\n",
    "\n",
    "size = 384\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)), \n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)), \n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5vqgjSAyMwT4"
   },
   "outputs": [],
   "source": [
    "# читаем датасет\n",
    "data_df = pd.read_csv(\"/media/murad/SSD/krasn/train_dataset_train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Ns9czMPFNxge",
    "outputId": "a10195bd-293a-406b-aa78-e3d379d1b5d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>sing1</th>\n",
       "      <th>sing2</th>\n",
       "      <th>sing3</th>\n",
       "      <th>sing4</th>\n",
       "      <th>sing5</th>\n",
       "      <th>sing6</th>\n",
       "      <th>sing7</th>\n",
       "      <th>sing8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>807</td>\n",
       "      <td>5-avi-frame24_jpg.rf.5dec372f9195e9a88ff7dd3bd...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>6-avi-frame6431_jpg.rf.1ad48ac0ce545b88cefb946...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130</td>\n",
       "      <td>9-avi-frame1457_jpg.rf.634a979898a9caa4d106913...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                img  sing1  sing2  \\\n",
       "0   807  5-avi-frame24_jpg.rf.5dec372f9195e9a88ff7dd3bd...      1      2   \n",
       "1   121  6-avi-frame6431_jpg.rf.1ad48ac0ce545b88cefb946...      8      0   \n",
       "2  1130  9-avi-frame1457_jpg.rf.634a979898a9caa4d106913...     21      0   \n",
       "\n",
       "   sing3  sing4  sing5  sing6  sing7  sing8  \n",
       "0     37      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILs-YFuYMyvW",
    "outputId": "1d9f4450-638e-4dce-ab2a-77e99d7e7d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающей выборки  778\n",
      "Тестовой выборки  388\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "print(\"Обучающей выборки \" ,len(listdir(\"/media/murad/SSD/krasn/train_dataset_train/train\")))\n",
    "print(\"Тестовой выборки \" ,len(listdir(\"/media/murad/SSD/krasn/test_dataset_test/test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-glCq25BODdU"
   },
   "outputs": [],
   "source": [
    "# разделим датасет на трейн и валидацию, чтобы смотреть на качество\n",
    "train_df, valid_df = train_test_split(data_df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zcp0qk5oPode"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, train_transform)\n",
    "valid_dataset = ImageDataset(valid_df, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ukJo2MSwPsWL"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=8)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=32,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0BTHTFrH-F6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlO_9AW_P0ad"
   },
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bLArr_igPxCj"
   },
   "outputs": [],
   "source": [
    "def crossvalid(res_model=None,criterion=None,optimizer=None,dataset=None,k_fold=5):\n",
    "    \n",
    "    train_score = pd.Series()\n",
    "    val_score = pd.Series()\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    fraction = 1/k_fold\n",
    "    seg = int(total_size * fraction)\n",
    "    # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset \n",
    "    # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
    "    for i in range(k_fold):\n",
    "        trll = 0\n",
    "        trlr = i * seg\n",
    "        vall = trlr\n",
    "        valr = i * seg + seg\n",
    "        trrl = valr\n",
    "        trrr = total_size\n",
    "        \n",
    "        train_left_indices = list(range(trll,trlr))\n",
    "        train_right_indices = list(range(trrl,trrr))\n",
    "        \n",
    "        train_indices = train_left_indices + train_right_indices\n",
    "        val_indices = list(range(vall,valr))\n",
    "        \n",
    "        train_set = torch.utils.data.dataset.Subset(dataset,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(dataset,val_indices)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=50,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=50,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "        train_acc = train(res_model,criterion,optimizer,train_loader,val_loader,1)\n",
    "        train_score.at[i] = train_acc\n",
    "        #val_acc = valid(res_model,criterion,optimizer,val_loader)\n",
    "        #val_score.at[i] = val_acc\n",
    "    \n",
    "    return train_score,val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qu_CF6TIP2ap"
   },
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history)\n",
    "    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n",
    "    \n",
    "    plt.scatter(steps, val_history, marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ac1V-EjHP8RT"
   },
   "outputs": [],
   "source": [
    "def train(res_model, criterion, optimizer, train_dataloader, test_dataloader, NUM_EPOCH=15):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    \n",
    "    train_acc_log = []\n",
    "    val_acc_log = []\n",
    "    \n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        print(f'Epoch - {epoch + 1}/{NUM_EPOCH}')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_size = 0\n",
    "        \n",
    "        train_pred = 0.\n",
    "        \n",
    "        correct = 0\n",
    "        l = len(train_dataloader)\n",
    "        for imgs, labels in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            #print(labels)\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_size += y_pred.size(0)\n",
    "            train_loss_log.append(loss.data / y_pred.size(0))\n",
    "\n",
    "            correct += (np.argmax(y_pred.cpu().detach().numpy()) == labels).float().sum()\n",
    "\n",
    "            optimizer.step()\n",
    "        accuracy = 100 * correct / l\n",
    "    # trainset, not train_loader\n",
    "    # probably x in your case\n",
    "\n",
    "        print(\"Accuracy = {}\".format(accuracy))\n",
    "\n",
    "        train_acc_log.append(train_pred / train_size)\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_size = 0\n",
    "        \n",
    "        val_pred = 0.\n",
    "        \n",
    "        model.eval()\n",
    "        val_pred = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "                \n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_size += pred.size(0)\n",
    "                \n",
    "                val_pred += (np.argmax(pred.cpu().detach().numpy()) == labels).float().sum()\n",
    "#                 val_pred += (np.argmax(y_pred.cpu().detach().numpy()) == labels).float().sum()\n",
    "\n",
    "        l = len(test_dataloader)\n",
    "        val_pred = 100 * val_pred / l\n",
    "        val_loss_log.append(val_loss / val_size)\n",
    "        val_acc_log.append(val_pred / val_size)\n",
    "\n",
    "        clear_output()\n",
    "#         plot_history(train_loss_log, val_loss_log, 'loss')\n",
    "        \n",
    "\n",
    "\n",
    "        print('Train loss:', (train_loss / train_size)*100)\n",
    "        print('Val loss:', (val_loss / val_size)*100)\n",
    "        print('Train acc:', accuracy)\n",
    "        print('Val acc:', val_pred)\n",
    "        \n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3g-ybm_WP_Pn"
   },
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DMSb-fY2P8hr"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ASE7TWDlQENp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_vit import ViT\n",
    "\n",
    "# Подгружаем модель\n",
    "model = ViT('L_32_imagenet1k', pretrained=True)\n",
    "\n",
    "model.fc = nn.Linear(1024, 70)\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (patch_embedding): Conv2d(3, 1024, kernel_size=(32, 32), stride=(32, 32))\n",
       "  (positional_embedding): PositionalEmbedding1D()\n",
       "  (transformer): Transformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (12): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (13): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (14): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (15): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (16): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (17): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (18): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (19): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (20): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (21): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (22): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (23): Block(\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (proj_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (pwff): PositionWiseFeedForward(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=1024, out_features=70, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GP66jae0QK0k"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-bmLtUuQ-LB",
    "outputId": "abde9637-2c61-414a-a6f3-7373038121a4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.481292672287613\n",
      "Val loss: 4.1085755213713036\n",
      "Train acc: tensor(0., device='cuda:0')\n",
      "Val acc: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, \n",
    "                                                                 criterion, \n",
    "                                                                optimizer, \n",
    "                                                                 train_loader, \n",
    "                                                                 valid_loader, \n",
    "                                                                 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaNlDfajYoeO"
   },
   "source": [
    "## Посмотрим метрики нашей итоговой модели на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "9PZw7XACUngH",
    "outputId": "a1781a32-1dc2-4e9e-e48a-0500cb35da6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/156 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|█████████████████████████████████████████| 156/156 [00:04<00:00, 42.43it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|█████████████████████████████████████████| 156/156 [00:04<00:00, 37.95it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=8)\n",
    "\n",
    "model.eval()\n",
    "valid_predicts = []\n",
    "\n",
    "for imgs, _ in tqdm(valid_loader):\n",
    "    \n",
    "    imgs = imgs.cuda()\n",
    "    pred = model(imgs)\n",
    "\n",
    "    pred_numpy = pred.cpu().detach().numpy()\n",
    "#     print(pred_nump6y.shape)\n",
    "    for class_obj in pred_numpy:\n",
    "      index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
    "      valid_predicts.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(valid_predicts).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "w6VefaPsbz7C",
    "outputId": "2f8c89b5-2161-49ec-ecb7-9a667fa430fb"
   },
   "outputs": [],
   "source": [
    "valid_df[\"pred\"] = valid_predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otsM09c7YzXD"
   },
   "source": [
    "# Посчитаем точность модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hPcG8jaGYvSL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "CREur-DyYvU3",
    "outputId": "4fc090e2-58af-4320-c256-98ce92799c2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  4,  5,  0,  0,  4,  4, 35,  4,  0,  0,  0,  0,  0,  1,  0, 35,\n",
       "        0, 58, 29, 35, 14,  0,  0,  4,  4, 33,  2,  0, 10,  1, 46, 16,  0,\n",
       "        0, 35,  4, 12, 45, 30, 35, 11,  0,  4,  4,  0, 35, 29,  4,  0, 10,\n",
       "        0,  4, 29,  2,  4,  0, 29,  4,  4,  0, 47,  4, 29,  1,  7,  0,  7,\n",
       "        1,  0,  0,  4,  0,  0,  0,  0, 35,  0, 14,  2, 35,  4,  0,  0, 30,\n",
       "       10, 35,  0,  4, 26,  0,  0,  4, 29,  0, 16,  1,  0,  0, 31,  4,  7,\n",
       "        0,  0,  0,  7, 29, 29,  0,  4,  2,  4,  4,  0,  4,  0, 19, 35,  4,\n",
       "        4, 15,  2,  0, 49,  0,  4,  0,  0, 10,  4,  4, 10,  7,  2,  0,  4,\n",
       "        0,  0,  1,  5, 29, 16, 16,  4,  0,  1, 35,  0, 12, 35,  0,  0,  5,\n",
       "       35,  0,  0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['pred'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "I15aOFkrcGtn",
    "outputId": "f6f215b1-695f-4d96-f037-de12ecc753ca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.3718917550953146\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = recall_score(valid_df['sing2'].values, valid_df['pred'].values, average='macro', zero_division  =0)\n",
    "print(f\"Validation accuracy = {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  4,  5, 14,  0,  4,  4,  0,  4,  5,  0,  0,  0,  0,  1, 10, 35,\n",
       "        0, 58, 29,  5,  4,  0,  0,  4,  4, 33, 10,  0, 10,  1, 10, 24,  0,\n",
       "        5,  5,  4,  1, 45, 29, 35,  2, 55,  4,  0,  0,  4, 29,  4,  0, 10,\n",
       "        0,  4, 29,  2,  4,  0, 29,  4,  5,  0, 16,  4, 29,  0,  7,  0,  1,\n",
       "        2,  0, 14,  4,  0,  0,  0,  0, 35,  0,  0, 49, 35, 51,  0,  0, 40,\n",
       "        4,  0,  2,  4, 27,  0,  4, 51, 26,  0, 16,  1,  0,  4, 31,  4,  0,\n",
       "        0,  0,  1, 10, 29, 29,  0,  0,  2,  4,  4,  5, 10,  0, 11, 35,  4,\n",
       "        4,  0,  2, 39, 49,  0,  4,  0,  0, 10,  0,  4, 10,  7,  2,  0, 15,\n",
       "        0,  0,  1,  5, 29, 16,  0,  4,  0,  2, 17,  0,  0, 35,  0,  0,  5,\n",
       "       35,  0,  0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['sing2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>754</td>\n",
       "      <td>6-avi-frame14887_jpg.rf.bb0bf6b4b122c23e1b33a9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>5-avi-frame2916_jpg.rf.1ecdbbc129d33896fd25b9b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1157</td>\n",
       "      <td>5-avi-frame2871_jpg.rf.f73998176f8a19ee03f8704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>6-avi-frame5752_jpg.rf.a067b0fc55b770c9b10bb7a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>715</td>\n",
       "      <td>6-avi-frame5678_jpg.rf.f140419d224703d49fe65db...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>243</td>\n",
       "      <td>3-avi-frame433_jpg.rf.b29d8fb61048b3016805a62e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>921</td>\n",
       "      <td>6-avi-frame4125_jpg.rf.e1dbdc7a7421bc9bc95a58f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>881</td>\n",
       "      <td>6-avi-frame1424_jpg.rf.e171549738da66b200b537c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>503</td>\n",
       "      <td>5-avi-frame2867_jpg.rf.c0bbb8942eeb6fac582e6b6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>599</td>\n",
       "      <td>6-avi-frame14403_jpg.rf.2da20f70e9a1360fe4753e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                img\n",
       "0     754  6-avi-frame14887_jpg.rf.bb0bf6b4b122c23e1b33a9...\n",
       "1      29  5-avi-frame2916_jpg.rf.1ecdbbc129d33896fd25b9b...\n",
       "2    1157  5-avi-frame2871_jpg.rf.f73998176f8a19ee03f8704...\n",
       "3    1049  6-avi-frame5752_jpg.rf.a067b0fc55b770c9b10bb7a...\n",
       "4     715  6-avi-frame5678_jpg.rf.f140419d224703d49fe65db...\n",
       "..    ...                                                ...\n",
       "383   243  3-avi-frame433_jpg.rf.b29d8fb61048b3016805a62e...\n",
       "384   921  6-avi-frame4125_jpg.rf.e1dbdc7a7421bc9bc95a58f...\n",
       "385   881  6-avi-frame1424_jpg.rf.e171549738da66b200b537c...\n",
       "386   503  5-avi-frame2867_jpg.rf.c0bbb8942eeb6fac582e6b6...\n",
       "387   599  6-avi-frame14403_jpg.rf.2da20f70e9a1360fe4753e...\n",
       "\n",
       "[388 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['img']\n",
    "        image = cv2.imread(f\"/media/murad/SSD/krasn/test_dataset_test_/test/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    \n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# читаем датасет\n",
    "test_df = pd.read_csv(\"/media/murad/SSD/krasn/test_dataset_test_/test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/388 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      " 99%|████████████████████████████████████████▊| 386/388 [00:09<00:00, 42.46it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|█████████████████████████████████████████| 388/388 [00:09<00:00, 40.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(test_df, test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=8)\n",
    "\n",
    "model.eval()\n",
    "test_predicts = []\n",
    "\n",
    "for imgs in tqdm(test_loader):\n",
    "    imgs = imgs.cuda()\n",
    "    pred = model(imgs)\n",
    "\n",
    "    pred_numpy = pred.cpu().detach().numpy()\n",
    "#     print(pred_nump6y.shape)\n",
    "    for class_obj in pred_numpy:\n",
    "      index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
    "      test_predicts.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sings_df = pd.read_csv('pred1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['id'] = sings_df['id']\n",
    "df['sing1'] = sings_df['sing1']\n",
    "df['sing2'] = test_predicts\n",
    "df['sing3'] = [0 for i in range(len(test_predicts))]\n",
    "df['sing4'] = [0 for i in range(len(test_predicts))]\n",
    "df['sing5'] = [0 for i in range(len(test_predicts))]\n",
    "df['sing6'] = [0 for i in range(len(test_predicts))]\n",
    "df['sing7'] = [0 for i in range(len(test_predicts))]\n",
    "df['sing8'] = [0 for i in range(len(test_predicts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pred2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/home/murad/models/model_sing2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sings_baseline.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
